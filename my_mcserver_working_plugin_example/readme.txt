this is my exact version working on my server. 

it is pointed to the minecraft-proxy-script as mentioned in SETUP-FOR-DUMMIES in my case running on port 3004/ai.
and assumes LM studio is running locally.

1-If you have the minecraft-proxy-script running on port 3004
2-make sure LM studio is running with Llama3.2 3b-instruct model(or any of those LLama 3.2 or 3.1 models) loaded.
3-make sure this JAR and folder is pasted in your Mc server/plugins folder and you running spigot you are all good to go.